{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "#import catboost\n",
    "import category_encoders as ce\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29813, 23)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reading df\n",
    "df = pd.read_csv('no_outlier_df.csv',index_col='id')\n",
    "df.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feautre Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "area                  0\n",
       "building_type         0\n",
       "building_nature       0\n",
       "num_bath_rooms        0\n",
       "num_bed_rooms         0\n",
       "price                 0\n",
       "purpose               0\n",
       "city                  0\n",
       "locality              0\n",
       "address            4680\n",
       "division              1\n",
       "zone                 80\n",
       "dtype: int64"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#setting out amenities to simplify the dataset and taking on important columns\n",
    "amenity_col = list(df.filter(like='amenity').columns)\n",
    "not_required_cols = ['property_description', 'property_overview', 'property_url', 'image_url']\n",
    "df.drop(columns=amenity_col+not_required_cols,inplace=True,axis=1)\n",
    "df.isna().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I am going to modify each feature using the insights given in task#3 EDA"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    29813.000000\n",
       "mean      1657.573696\n",
       "std       1215.077508\n",
       "min         93.000000\n",
       "25%       1050.000000\n",
       "50%       1350.000000\n",
       "75%       2000.000000\n",
       "max      17000.000000\n",
       "Name: area, dtype: float64"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['area'].describe()\n",
    "#nothing to do here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### building_type"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Nearly 80% of our properties are `Apartment`, for a total of nearly 27000 samples. We also some `Office`, `Building`, `Shop`, `Floor`, `Residential Plot`, whose number are under 10% of the total dataset; that is to say, their numbers are under 2500. \n",
    "2. There are other types of properties, in a very negligible number.\n",
    "\n",
    "❗ **Recommendation**:\n",
    "* We are expecting our future models to perform well on `Apartment`, and to have and acceptable result for `Office`, `Building`, `Shop`, `Floor`, `Residential Plot`. They are expected to perform poorly on other types of properties.\n",
    "* Types not part of (1) should be dropped in order to avoid noise in our future models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "req_building_type = ['Apartment','Office', 'Building', 'Shop', 'Floor', 'Residential Plot']\n",
    "df = df[df['building_type'].isin(req_building_type)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### building_nature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count           29637\n",
       "unique              2\n",
       "top       Residential\n",
       "freq            23985\n",
       "Name: building_nature, dtype: object"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['building_nature'].describe()\n",
    "#nothing to do here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### num_bath_rooms & num_bed_rooms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_bath_rooms</th>\n",
       "      <th>num_bed_rooms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>29637.000000</td>\n",
       "      <td>29637.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.660694</td>\n",
       "      <td>2.316800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.551060</td>\n",
       "      <td>1.268307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       num_bath_rooms  num_bed_rooms\n",
       "count    29637.000000   29637.000000\n",
       "mean         1.660694       2.316800\n",
       "std          1.551060       1.268307\n",
       "min          0.000000       0.000000\n",
       "25%          0.000000       2.000000\n",
       "50%          2.000000       3.000000\n",
       "75%          3.000000       3.000000\n",
       "max         10.000000      10.000000"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['num_bath_rooms','num_bed_rooms']].describe()\n",
    "#nothing to do here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    2.963700e+04\n",
       "mean     3.572601e+06\n",
       "std      5.929573e+06\n",
       "min      4.200000e+03\n",
       "25%      2.500000e+04\n",
       "50%      1.300000e+05\n",
       "75%      6.000000e+06\n",
       "max      1.200000e+08\n",
       "Name: price, dtype: float64"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['price'].describe()\n",
    "#non-linear relation was observed with every feature\n",
    "#nothing to do here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### purpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     29637\n",
       "unique        2\n",
       "top        Rent\n",
       "freq      17727\n",
       "Name: purpose, dtype: object"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#nothing to do here\n",
    "df['purpose'].describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### city"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Most of our properties are in `Dhaka`, for a total of nearly 28,000 properties. We also have nearly 4000 properties in `Chattogram`.     \n",
    "1. A negligible amount of properties are in `Narayanganj City`, `Barishal`, `Gazipur`, each of them with a count below 500 properties ..\n",
    "1. As for the other cities, their properties count is too insignificant.\n",
    "\n",
    "❗ **Recommendation**:\n",
    "* We are expecting our future models not to be perform well on cities mentioned in (2). We should consider dropping samples with those cities when building models since their low number will make it so that the models will not predict well on them. \n",
    "* Cities not part of (1) and (2) should definitively be dropped in order to avoid noise in our future models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29346, 12)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "req_city = ['Dhaka','Chattogram','Narayanganj City', 'Barishal','Gazipur']\n",
    "df = df[df['city'].isin(req_city)]\n",
    "df.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### locality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count      29346\n",
       "unique       160\n",
       "top       Mirpur\n",
       "freq        4966\n",
       "Name: locality, dtype: object"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#nothing to do here\n",
    "df['locality'].describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([12731,   413,   212,   193,   184,   173,   164,   153,   152,\n",
       "         150,   147,   141,   139,   139,   139,   127,   123,   120,\n",
       "         119,   114,   111,   109,   108,   106,   105,   103,   101,\n",
       "         100,    99,    99], dtype=int64)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['address'].value_counts()[:30].values\n",
    "#there is error, bangladesh should not be included in a address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.replace('Bangladesh',np.nan, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "778"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df['address'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17350"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['address'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this feature doesn't see like a meaningfull for price prediction better droping as it may cause high dimensionality \n",
    "df.drop(columns='address', inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### divison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dhaka         25780\n",
       "Chattogram     3344\n",
       "Barisal         222\n",
       "Name: division, dtype: int64"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['division'].value_counts()\n",
    "#nothing to do here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['zone'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dhaka    80\n",
       "Name: division, dtype: int64"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['zone'].isna()]['division'].value_counts()\n",
    "#all missing zones belong to dhaka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "#it won't be wrong to fill them with mode\n",
    "df['zone'].fillna(df['zone'].mode(), inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns='price', axis=1)\n",
    "y = df['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Categorical Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 23476 entries, bproperty-10419 to bdhousing-162\n",
      "Data columns (total 10 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   area             23476 non-null  float64\n",
      " 1   building_type    23476 non-null  object \n",
      " 2   building_nature  23476 non-null  object \n",
      " 3   num_bath_rooms   23476 non-null  float64\n",
      " 4   num_bed_rooms    23476 non-null  float64\n",
      " 5   purpose          23476 non-null  object \n",
      " 6   city             23476 non-null  object \n",
      " 7   locality         23476 non-null  object \n",
      " 8   division         23476 non-null  object \n",
      " 9   zone             23409 non-null  object \n",
      "dtypes: float64(3), object(7)\n",
      "memory usage: 2.0+ MB\n"
     ]
    }
   ],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is observed that locality and zone have high no. of unique features.\n",
    "\n",
    "Therefore, a distinct technique will be employed to handle features with fewer than 10 unique values as compared to those with more than 10.\n",
    "\n",
    "=> using OneHotEncoder/get_dummies for less than 10 \n",
    "\n",
    "=> using CatBoost encoding for greater than 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dividing the columns based on no. of unique values\n",
    "cat_cols = list(X_train.select_dtypes(include=['object']).columns)\n",
    "num_cols = list(X_train.select_dtypes(include='number').columns)\n",
    "large_cat = ['zone', 'locality']\n",
    "small_cat = [item for item in cat_cols if item not in large_cat]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OneHot_encoding/get_dummies (small features)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#small_cat columns encoded\n",
    "encode_small_cat_df = pd.get_dummies(train_set[small_cat], drop_first=True)\n",
    "encode_small_cat_df.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### catboost encoding (large features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CatBoostEncoder(cols=['zone', 'locality'])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#large_cat columns encoded\n",
    "cat_boost_encoder = ce.CatBoostEncoder()\n",
    "cat_boost_encoder.fit(X_train[large_cat],y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating encoded df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#adding cols of small encoded features\n",
    "encoded_train_set = pd.concat([train_set,encode_small_cat_df],axis=1)\n",
    "encoded_train_set.drop(columns=small_cat,inplace=True,axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#adding cols of large encoded feautures\n",
    "encoded_train_set[['encoded_zone', 'encoded_locality']] = cat_boost_encoder.transform(train_set[large_cat])\n",
    "encoded_train_set = encoded_train_set.drop(columns=['zone','locality'], axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "encoded_train_set.head().T"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "encoded_train_set.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Scaling"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X_train = encoded_train_set.drop(columns='price', axis=1)\n",
    "y_train = encoded_train_set['price'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Applying Standarization\n",
    "s_scaler = StandardScaler()\n",
    "\n",
    "s_scaler.fit(X_train[num_cols])\n",
    "#X_train_scaled = s_scaler.transform(X_train[num_cols])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to be done"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "new_cols = []\n",
    "class DfDivider(BaseEstimator, TransformerMixin):\n",
    "    cat_cols = []\n",
    "    num_cols = []\n",
    "    small_cat = []\n",
    "    large_cat = []\n",
    "\n",
    "    def __init__(self):\n",
    "        self\n",
    "    def fit(self, X=None, y=None):\n",
    "        return self\n",
    "    def transform(self, df):\n",
    "        DfDivider.cat_cols = list(df.select_dtypes(include=['object']).columns)\n",
    "        DfDivider.num_cols = list(df.select_dtypes(include='number').columns)\n",
    "        DfDivider.large_cat = ['zone', 'locality']\n",
    "        DfDivider.small_cat = [item for item in cat_cols if item not in DfDivider.large_cat]\n",
    "        return df\n",
    "\n",
    "class SmallFeatureEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self\n",
    "    def fit(self, X=None, y=None):\n",
    "        return self\n",
    "    def transform(self, df):\n",
    "        encode_small_cat_df = pd.get_dummies(df[DfDivider.small_cat], drop_first=True)\n",
    "        encoded_df = pd.concat([df,encode_small_cat_df],axis=1)\n",
    "        encoded_df.drop(columns=DfDivider.small_cat,inplace=True,axis=1)\n",
    "        return encoded_df\n",
    "    \n",
    "class LargeFeatureEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self\n",
    "    def fit(self, X=None, y=None):\n",
    "        return self\n",
    "    def transform(self, df):\n",
    "        df[['encoded_zone', 'encoded_locality']] = cat_boost_encoder.transform(df[DfDivider.large_cat])\n",
    "        df = df.drop(columns=['zone','locality'], axis=1)\n",
    "        return df\n",
    "    \n",
    "class FeatureScaler(BaseEstimator,TransformerMixin):\n",
    "    #DfDivider.num_cols.remove('price')\n",
    "    def __init__(self):\n",
    "        self\n",
    "    def fit(self, X=None, y=None):\n",
    "        return self\n",
    "    def transform(self, df):\n",
    "        X = df.drop(columns='price', axis=1)\n",
    "        y = df['price'].copy()\n",
    "        X_scaled = s_scaler.transform(X)\n",
    "        X_scaled_df = pd.DataFrame(X_scaled, columns=X[num_cols].columns, index=X[num_cols].index)\n",
    "        return df\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "encoding_pipeline = Pipeline([\n",
    "    ('df_divider', DfDivider()),\n",
    "    ('small_cat_encder', SmallFeatureEncoder()),\n",
    "    ('large_cat_encoder', LargeFeatureEncoder()) \n",
    "])\n",
    "scaling_pipeline = Pipeline([\n",
    "    ('std_scaler', StandardScaler())\n",
    "])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Columns Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "full_pipeline = ColumnTransformer([\n",
    "    ('encoding', encoding_pipeline, cat_cols),\n",
    "    ('scaling', scaling_pipeline, num_cols)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.        ,  0.        , ...,  2.42289354,\n",
       "        -1.06208103, -1.82446843],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.55411628,\n",
       "         1.51062849,  0.5402425 ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.03085864,\n",
       "        -1.06208103,  0.5402425 ],\n",
       "       ...,\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.6390607 ,\n",
       "         1.51062849,  0.5402425 ],\n",
       "       [ 0.        ,  0.        ,  0.        , ..., -0.45672234,\n",
       "        -1.06208103,  0.5402425 ],\n",
       "       [ 0.        ,  0.        ,  0.        , ..., -0.47541011,\n",
       "         0.86745111,  0.5402425 ]])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prepared_x_train = full_pipeline.fit_transform(X_train)\n",
    "prepared_x_train"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exporting ready data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#converting encoded data to DataFrame\n",
    "X_train_scaled_df = pd.DataFrame(X_train_scaled,columns=X_train.columns, index=X_train.index)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#new x_train\n",
    "new_train_set = pd.concat([X_train_scaled_df,y_train],axis=1)\n",
    "new_train_set.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### this part will be done using tranformers, for now i m doing it manually"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#encoding the test_set\n",
    "encoded_small_test_set = pd.get_dummies(test_set[small_cat], drop_first=True)\n",
    "encoded_test_set = pd.concat([test_set,encoded_small_test_set],axis=1)\n",
    "encoded_test_set.drop(columns=small_cat,inplace=True,axis=1)\n",
    "encoded_test_set[['encoded_zone', 'encoded_locality']] = cat_boost_encoder.transform(test_set[large_cat])\n",
    "encoded_test_set = encoded_test_set.drop(columns=['zone','locality'], axis=1)\n",
    "\n",
    "X_test = encoded_test_set.drop(columns='price', axis=1)\n",
    "y_test = encoded_test_set['price'].copy()\n",
    "\n",
    "X_test_scaled = s_scaler.transform(X_test)\n",
    "#converting encoded data to DataFrame\n",
    "X_test_scaled_df = pd.DataFrame(X_test_scaled,columns=X_test.columns, index=X_test.index)\n",
    "new_test_set = pd.concat([X_test_scaled_df,y_test],axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#exporting\n",
    "ready_df = pd.concat([new_train_set,new_test_set])\n",
    "print(ready_df.shape)\n",
    "ready_df.to_csv('encoded_scaled_df_no_amenity.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Development\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lin_reg = LinearRegression()\n",
    "#lin_reg.fit(X)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
