{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: category_encoders in c:\\users\\saran\\anaconda3\\lib\\site-packages (2.6.0)\n",
      "Requirement already satisfied: scipy>=1.0.0 in c:\\users\\saran\\anaconda3\\lib\\site-packages (from category_encoders) (1.9.1)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in c:\\users\\saran\\anaconda3\\lib\\site-packages (from category_encoders) (1.0.2)\n",
      "Requirement already satisfied: numpy>=1.14.0 in c:\\users\\saran\\anaconda3\\lib\\site-packages (from category_encoders) (1.21.5)\n",
      "Requirement already satisfied: pandas>=1.0.5 in c:\\users\\saran\\anaconda3\\lib\\site-packages (from category_encoders) (1.4.4)\n",
      "Requirement already satisfied: patsy>=0.5.1 in c:\\users\\saran\\anaconda3\\lib\\site-packages (from category_encoders) (0.5.2)\n",
      "Requirement already satisfied: statsmodels>=0.9.0 in c:\\users\\saran\\anaconda3\\lib\\site-packages (from category_encoders) (0.13.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\saran\\anaconda3\\lib\\site-packages (from pandas>=1.0.5->category_encoders) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\saran\\anaconda3\\lib\\site-packages (from pandas>=1.0.5->category_encoders) (2022.1)\n",
      "Requirement already satisfied: six in c:\\users\\saran\\anaconda3\\lib\\site-packages (from patsy>=0.5.1->category_encoders) (1.16.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\saran\\anaconda3\\lib\\site-packages (from scikit-learn>=0.20.0->category_encoders) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\saran\\anaconda3\\lib\\site-packages (from scikit-learn>=0.20.0->category_encoders) (2.2.0)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\users\\saran\\anaconda3\\lib\\site-packages (from statsmodels>=0.9.0->category_encoders) (21.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\saran\\anaconda3\\lib\\site-packages (from packaging>=21.3->statsmodels>=0.9.0->category_encoders) (3.0.9)\n",
      "Requirement already satisfied: joblib in c:\\users\\saran\\anaconda3\\lib\\site-packages (1.1.0)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "!pip install category_encoders\n",
    "import category_encoders as ce\n",
    "!pip install joblib\n",
    "import joblib\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading df\n",
    "df = pd.read_csv('prepare_df.csv',index_col='id')\n",
    "amenities = df.filter(like='amenity')\n",
    "df.drop(columns=amenities.columns, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area</th>\n",
       "      <th>building_type</th>\n",
       "      <th>building_nature</th>\n",
       "      <th>num_bath_rooms</th>\n",
       "      <th>num_bed_rooms</th>\n",
       "      <th>price</th>\n",
       "      <th>purpose</th>\n",
       "      <th>city</th>\n",
       "      <th>locality</th>\n",
       "      <th>division</th>\n",
       "      <th>zone</th>\n",
       "      <th>price_log</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bproperty-14087</th>\n",
       "      <td>1100.0</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>Residential</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>22000.0</td>\n",
       "      <td>Rent</td>\n",
       "      <td>Dhaka</td>\n",
       "      <td>Mohammadpur</td>\n",
       "      <td>Dhaka</td>\n",
       "      <td>Mohammadpur</td>\n",
       "      <td>9.998798</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   area building_type building_nature  num_bath_rooms  \\\n",
       "id                                                                      \n",
       "bproperty-14087  1100.0     Apartment     Residential             3.0   \n",
       "\n",
       "                 num_bed_rooms    price purpose   city     locality division  \\\n",
       "id                                                                             \n",
       "bproperty-14087            3.0  22000.0    Rent  Dhaka  Mohammadpur    Dhaka   \n",
       "\n",
       "                        zone  price_log  \n",
       "id                                       \n",
       "bproperty-14087  Mohammadpur   9.998798  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Apartment', 'Residential Plot', 'Building', 'Shop', 'Office',\n",
       "       'Floor'], dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['building_type'].unique()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = df.drop(columns=['price','price_log'], axis=1)\n",
    "train_y = df['price_log']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dividing and Selecting_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "amenity_col = list(df.filter(like='amenity').columns)\n",
    "cat_cols = list(set(df.select_dtypes(include=['object']).columns) - set(['city', 'locality']))\n",
    "num_cols = list(set(df.select_dtypes(include='number').columns) - set(['price', 'price_log']) - set(amenity_col))\n",
    "large_cat = ['zone']\n",
    "small_cat = list(set(cat_cols) - set(large_cat))\n",
    "number_cols = list(set(num_cols) - set(['city', 'locality']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['division', 'building_type', 'building_nature', 'purpose'],\n",
       " ['zone'],\n",
       " ['area', 'num_bath_rooms', 'num_bed_rooms'])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_cat, large_cat, number_cols"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class CatBoostEncoderTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns=None):\n",
    "        self.columns = columns\n",
    "        self.encoders = {}\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        for col in self.columns:\n",
    "            encoder = ce.CatBoostEncoder()\n",
    "            encoder.fit(X[col], y)\n",
    "            self.encoders[col] = encoder\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        transformed_X = X.copy()\n",
    "        \n",
    "        for col, encoder in self.encoders.items():\n",
    "            transformed_X[col] = encoder.transform(X[col])\n",
    "        \n",
    "        return transformed_X\n",
    "\n",
    "class OneHotEncoderTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns=None, drop_original=True):\n",
    "        self.columns = columns\n",
    "        self.drop_original = drop_original\n",
    "        self.encoder = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "        self.new_columns = None\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        if self.columns is None:\n",
    "            global small_cat\n",
    "            self.columns = small_cat.tolist()\n",
    "        \n",
    "        self.encoder.fit(X[self.columns])\n",
    "        self.new_columns = self.encoder.get_feature_names_out(self.columns)\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        transformed_X = pd.DataFrame(self.encoder.transform(X[self.columns]), columns=self.new_columns, index=X.index)\n",
    "        \n",
    "        if self.drop_original:\n",
    "            transformed_X = X.drop(columns=self.columns).join(transformed_X)\n",
    "        \n",
    "        return transformed_X\n",
    "    \n",
    "class NumberColsStandardScaler(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, number_cols=None):\n",
    "        self.number_cols = number_cols\n",
    "        self.scaler = StandardScaler()\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        if self.number_cols is None:\n",
    "            self.number_cols = X.select_dtypes(include='number').columns.tolist()\n",
    "        \n",
    "        self.scaler.fit(X[self.number_cols])\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        transformed_X = X.copy()\n",
    "        transformed_X[self.number_cols] = self.scaler.transform(X[self.number_cols])\n",
    "        \n",
    "        return transformed_X\n",
    "        \n",
    "class PassAmenityColumns(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self\n",
    "    def fit(self, X=None, y=None):\n",
    "        return self\n",
    "    def transform(self, df):\n",
    "        return df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Columns Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "large_cat_transformer = CatBoostEncoderTransformer(columns=large_cat)\n",
    "Transformed_large_cat = large_cat_transformer.fit_transform(train_X[large_cat], train_y)\n",
    "number_cols.append('zone')\n",
    "train_X['zone'] = Transformed_large_cat['zone']\n",
    "small_cat_transformer = OneHotEncoderTransformer(columns=small_cat,drop_original=True)\n",
    "scaler_transformer = NumberColsStandardScaler(number_cols=number_cols)\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers=[ \n",
    "    ('small_cat', small_cat_transformer, small_cat),\n",
    "    ('scaling', scaler_transformer, number_cols)\n",
    "    #('pass_amenity_cols', PassAmenityColumns(), amenity_col)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepared_train_x = preprocessor.fit_transform(train_X,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "full_pipeline = Pipeline(steps=[\n",
    "    ('preprocessing', preprocessor)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_input_for_model(x):\n",
    "    x_large_preapered = large_cat_transformer.transform(x)\n",
    "    x['zone'] = x_large_preapered['zone']\n",
    "    x = preprocessor.transform(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RandomForrest_sarang']"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "rf_reg = RandomForestRegressor(max_features=8, n_estimators =15)\n",
    "rf_reg.fit(prepared_train_x,train_y)\n",
    "joblib.dump(rf_reg,'RandomForrest_sarang')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.043760772474336636"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = rf_reg.predict(prepared_train_x)\n",
    "rf_reg_mse = mean_squared_error(train_y, predictions)\n",
    "rf_reg_rmse = np.sqrt(rf_reg_mse)\n",
    "rf_reg_mse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_prediction(input):\n",
    "    input = pd.DataFrame(input, index=[0])\n",
    "    prepared_input = prepare_input_for_model(x=input)\n",
    "    model = joblib.load('RandomForrest_sarang')\n",
    "    prediction = model.predict(prepared_input)\n",
    "    antilog_price = np.exp(prediction)\n",
    "    \n",
    "    return int(antilog_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicte_price = make_prediction({\n",
    "            'division':'Dhaka', #Dhaka/Chattogram/Barisal\n",
    "            'building_type':'Appartment', #Apartment/Office/Building/Floor/Shop/Residential Plot\n",
    "            'building_nature':'Residnetial', #Residential/Commercia\n",
    "            'purpose':'Sale', #Sale/Rent \n",
    "            'zone':'Mirpur', #any zone\n",
    "            'num_bed_rooms':3, #numerical value\n",
    "            'num_bath_rooms':2, #numerical value\n",
    "            'area':2500 #numerical value\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16324925"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicte_price"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
